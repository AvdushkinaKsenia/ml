SVM — это алгоритм ML, который классифицирует данные путем нахождения оптимальной линии или гиперплоскости, которая максимизирует расстояние между каждым классом в N-мерном пространстве.
Данный метод классификации, который ищет гиперплоскость, разделяющую классы с максимальным зазором (маржей).
Цель алгоритма SVM: найти линию (или границу решения), которая может разделить n-мерное пространство на классы, чтобы можно было поместить новые точки данных в правильный класс. Эта граница решения называется ГИПЕРПЛОСКОСТЬЮ.

Линейный SVM: используется с линейно разделяемыми данными; это означает, что данные не должны подвергаться каким-либо преобразованиям для разделения на разные классы. Точки данных можно легко разделить линейной линией. Мощный инструмент для задач классификации с четкими линейными границами.
Нелинейный SVM: точки данных нелегко разделить линейной линией. SVM может эффективно выполнять нелинейную классификацию, используя трюк с ядром (kernel trick). Это позволяет неявно отображать входные данные в многомерные пространства признаков.

Если данные нелинейно разделимы, вводят "мягкий" зазор (slack variables ξ). Классификация с "мягкой маржой" добавляет штраф (C) к целевой функции за ошибочно классифицированные наблюдения в обучающем наборе. По сути, алгоритм SVM выберет границу решения, которая оптимизирует компромисс между более широким зазором и меньшим общим штрафом за ошибку.

Ядерный трюк (kernel function) - метод в ML, позволяющий перевести элементы для случая линейной неразделимости в новое линейно разделимое пространство (называемое спрямляющим пространством).