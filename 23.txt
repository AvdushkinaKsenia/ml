Сверточные нейронные сети (CNN) стали ключевым инструментом в обработке изображений благодаря их способности автоматически выявлять пространственные иерархии, такие как края, текстуры и формы, без необходимости ручного выбора признаков. Это особенно важно для задач, таких как классификация изображений, обнаружение объектов и сегментация.

Популярные архитектуры сверточных НС:
1. AlexNet (2012): Одна из первых глубоких CNN, победившая в конкурсе ImageNet, с 5 сверточными и 3 полносвязными слоями, использующая ReLU и dropout для предотвращения переобучения.
2. VGG (2014): Показала важность глубины, используя 16 или 19 слоев с небольшими фильтрами 3x3, что сделало сеть глубокой, но эффективной.
3. Inception (GoogLeNet, 2014): Ввела модули Inception, которые одновременно применяют фильтры разных размеров для захвата признаков на разных масштабах, с меньшим количеством параметров.
4. ResNet (2015): Использовала остаточные связи (skip connections), чтобы обучать очень глубокие сети (до 152 слоев), решая проблему исчезающего градиента.

Трансферное обучение — это техника, при которой модель, предварительно обученная на большом наборе данных, дообучается на меньшем наборе данных для конкретной задачи. Это позволяет использовать общие признаки, изученные в нижних слоях сети, такие как края и текстуры, для новых задач, таких как классификация медицинских изображений или распознавание лиц. Процесс включает замораживание нижних слоев и обучение только верхних слоев или добавление новых слоев, что значительно сокращает время обучения и улучшает результаты.
