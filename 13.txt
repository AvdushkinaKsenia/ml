ДЕРЕВО РЕШЕНИЙ — это непараметрический контролируемый метод обучения, используемый для классификации и регрессии. Чаще всего применяются для задач классификации.
ЦЕЛЬ состоит в том, чтобы создать модель, которая предсказывает значение целевой переменной путем изучения простых правил принятия решений, выведенных из характеристик (признаков) данных.

ДРЕВОВИДНЫЕ АЛГОРИТМЫ:
1. ID3 (Iterative Dichotomiser 3) Использует энтропию и прирост информации для оценки разделения признаков. Работает только с категориальными признаками. Деревья выращиваются до максимального размера с последующей обрезкой для улучшения обобщающей способности.
2. C4.5 Преемник ID3, устраняет ограничение на категориальные признаки. Автоматически преобразует непрерывные признаки в дискретные интервалы. Выполняет обрезку путем удаления условий, не улучшающих точность.
3. C5.0 Улучшенная версия C4.5. Требует меньше памяти. Создает более компактные наборы правил. Демонстрирует более высокую точность.
4. CART (Classification and Regression Trees) Поддерживает как классификацию, так и регрессию. Не генерирует правила, только деревья решений.

Процесс построения дерева решений:
1. Для каждого атрибута в наборе данных алгоритм DT формирует узел. Самый важный атрибут размещается в корневом узле (Root Node).
2. Для оценки поставленной задачи старт с корневого узла и продвижение вниз по дереву, следуя за соответствующим узлом (Decision Node), который соответствует условию или решению.
3. Этот процесс продолжается до тех пор, пока не будет достигнут листовой узел (Leaf Node), содержащий прогноз DT.

Энтропия — это мера неопределенности в наборе данных.
Прирост информации — уменьшение энтропии. Прирост информации вычисляет разницу между энтропией до разделения и средней энтропией после разделения набора данных на основе заданных значений атрибутов.
Индекс Джини (Gini Index): это вероятность неправильной классификации случайной точки данных в наборе данных, если она была помечена на основе распределения классов набора данных. Измеряет степень неравномерности распределения классов.

Чтобы избежать переобучения, в модель дерева решений можно добавить параметры регуляризации:
max_depth: максимальная глубина дерева.
max_features: максимальное количество признаков, которые будут рассматриваться при каждом разбиении.
max_leaf_nodes: максимальное количество узлов листьев.
min_impurity_decrease: минимальное снижение примеси, необходимое для разделения узла.
min_samples_leaf: минимальное количество образцов, которое должно быть в узле-листе.
min_samples_split: минимальное число образцов, необходимое для разделения узла.
ccp_alpha: параметр, который штрафует за сложность дерева.
Criterion: определяет функцию потерь, которая будет использоваться для оценки качества разбиения на каждом узле дерева.