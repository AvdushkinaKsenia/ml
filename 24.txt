ЗАДАЧА ПОНИЖЕНИЯ РАЗМЕРНОСТИ -одна из важнейших в анализе данных и ML,может возникнуть в двух следующих случаях.
1. Визуализация: при работе с многомерными данными необходимо посмотреть на их структуру, уменьшив размерность.
2. Предобработка признаков в моделях ML: неудобно обучать алгоритмы на сотне признаков, среди которых может быть множество зашумленных и/или линейно зависимых (от них лучше избавиться).
СНИЖЕНИЕ РАЗМЕРНОСТИ ДАННЫХ – семейство методов, используемых в анализе и моделировании данных для уменьшения сложности данных при максимальном сохранении их исходной информативности.

МЕТОД ГЛАВНЫХ КОМПОНЕНТ — один из основных способов в ML уменьшить размерность данных, потеряв наименьшее количество информации. 
ГЛАВНЫЕ КОМПОНЕНТЫ — новые переменные, с помощью которых будут описывать объекты.

МЕТОД ГЛАВНЫХ КОМПОНЕНТ
1. Стандартизация данных.
2. Вычисление ковариационной матрицы.
3. Вычисление собственных векторов и собственных значений ковариационной матрицы.
4. Сортировка пар <собственное значение, собственный вектор> по убыванию. Чем больше число, тем больше дисперсия.
5. Выбор первых k пар <собственное значение, собственный вектор>, где k — размерность целевого пространства.
6. Матрица, составленная из k собственных векторов — матрица преобразования из данного пространства в пространство с размерностью k. Берем N первых собственных векторов, которые соответствуют первым N собственным числам. Это и есть искомые главные компоненты.
7. Чтобы произвести понижение размерности следует умножить матрицу стандартизованных входных данных (результат п. 1) на матрицу из k собственных векторов (результат п. 6).

Ядровой PCA — это способ «уловить» в данных скрытые, изогнутые формы, когда обычный PCA не справляется. 

